from collections import defaultdict
import math
from datetime import datetime
import sys
import argparse
import pysam
import numpy
import numpy.ma as ma
import matplotlib
matplotlib.use("Agg")
from matplotlib import pyplot as plt
import scipy
from scipy import stats

class Reference:
    def __init__(self, chrom_list):
        self.chroms = chrom_list
        self.chrom_names = ["chr"+str(i+1) for i in range(22)] + ["chrX", "chrY"]
        self.chr_idx = {self.chroms[c]:c for c in range(len(self.chroms))}
        for c in range(len(self.chrom_names)):
            self.chr_idx[self.chrom_names[c]] = c
        self.chr_len = [None for c in self.chroms]
        self.chr_covg = [None for c in self.chroms]

hg38 = Reference(["NC_000001.11", "NC_000002.12", "NC_000003.12", "NC_000004.12", "NC_000005.10", "NC_000006.12", "NC_000007.14", "NC_000008.11", "NC_000009.12", "NC_000010.11", "NC_000011.10", "NC_000012.12", "NC_000013.11", "NC_000014.9", "NC_000015.10", "NC_000016.10", "NC_000017.11", "NC_000018.10", "NC_000019.10", "NC_000020.11", "NC_000021.9", "NC_000022.11", "NC_000023.11", "NC_000024.10"])
t2t = Reference(["NC_060925.1", "NC_060926.1", "NC_060927.1", "NC_060928.1", "NC_060929.1", "NC_060930.1", "NC_060931.1", "NC_060932.1", "NC_060933.1", "NC_060934.1", "NC_060935.1", "NC_060936.1", "NC_060937.1", "NC_060938.1", "NC_060939.1", "NC_060940.1", "NC_060941.1", "NC_060942.1", "NC_060943.1", "NC_060944.1", "NC_060945.1", "NC_060946.1", "NC_060947.1", "NC_060948.1"])

sbin_size = 1000000 # small bin size - has to be big enough to typically have >= 1 read, even at minimum coverage
bin_size = 1000000
min_anchor = 500
gene_margin = 5000
enrich_margin = 50000

def main(bam_file, bed_file, repeatmasker_file, outfig, read_lim=None, outdir=None, run_full_analysis=False, eval_genes=[]):

    # check BED file for the appropriate reference to use
    test_chrom = open(bed_file).readline().split('\t')[0]
    if test_chrom in hg38.chroms:
        ref = hg38
        sys.stderr.write("Detected reference: GRCh38\n")
    elif test_chrom in t2t.chroms:
        ref = t2t
        sys.stderr.write("Detected reference: T2T/CHM13v2\n")
    else:
        sys.stderr.write(f"ERROR: '{test_chrom}' not found in hg38 or T2T accessions\n")
        sys.exit(1)

    mask = [[] for i in range(len(ref.chroms))]

    sys.stderr.write("Reading repeats...\n")
    # collect repeats from repeatmasker file and Ns
    repeats = {}
    with open(repeatmasker_file) as rf:
        for line in rf:
            parts = line.strip().split('\t')
            chrom, st, en = parts[0], int(parts[1]), int(parts[2])
            if chrom not in ref.chrom_names:
                continue
            chrom = ref.chrom_names.index(chrom)
            if chrom not in repeats:
                repeats[chrom] = []
            repeats[chrom].append((st,en))
            mask[chrom].append((st,en))

    sys.stderr.write("Reading target genes...\n")
    # collect enriched gene set
    genes = defaultdict(list)
    for line in open(bed_file):
        parts = line.strip().split('\t')
        chrom, st, en, gene = parts[:4]
        chrom = ref.chroms.index(chrom)
        genes[chrom].append((gene, int(st), int(en)))
        mask[chrom].append((int(st), int(en)))

    # sort masked features by start position
    for i in range(len(mask)):
        mask[i].sort(key = lambda a: a[0])

    last = None
    hits = defaultdict(list)
    read_lengths = {}
    total = 0
    total_ovl = 0
    total_on_target = 0
    reads_on_target = 0
    reads_off_target = 0
    long_off_target = 0
    gene_covg = defaultdict(int)

    if outdir is not None:
        sys.stderr.write(f"Writing on-target PAF to {outdir}/on_target.paf\n")
        target_paf = open(f"{outdir}/on_target.paf", 'w')

    sys.stderr.write("Reading BAM file...\n")
    # !!!! BAM files do not follow our normal assumptions from PAF files that all alignments of a reads are together - this is routinely violated in a BAM generated by dorado!
    # ignore apparently truncated BAM files so that it can be run on in-progress runs
    try:
        af = pysam.AlignmentFile(bam_file, mode='rb', ignore_truncation=True)
    except FileNotFoundError as e:
        sys.stderr.write(f"Error: File not found: {bam_file}\n")
        sys.exit(1)

    if ref.chroms[0] in af.references:
        bam_names = "accessions"
    elif ref.chrom_names[0] in af.references:
        bam_names = "chr"
    # check if it's sorted and indexed
    try:
        af.fetch(ref.chroms[0] if bam_names == "accessions" else ref.chrom_names[0], 0, 1000)
    except Exception as e:
        sys.stderr.write(f"ERROR: {e}\n")
        sys.stderr.write("  appears unsorted, will continue but will be slow...\n")
        # BAM is not sorted, go through the whole thing... slowly
        regions = [af.fetch(until_eof=True)]
    else:
        sys.stderr.write("  appears to be sorted and indexed, thanks!\n")
        if not run_full_analysis:
            sys.stderr.write("  analyzing on-target gene regions only... adaptive sampling stats and karyotype will be WRONG, run with --full to fix them")
            # BAM is sorted, get just gene regions
            regions = [af.fetch(ref.chroms[ch] if bam_names == "accessions" else ref.chrom_names[ch], st, en) for ch in genes for gene, st, en in genes[ch] if len(eval_genes) == 0 or gene.lower() in eval_genes]
        else:
            regions = [af.fetch(until_eof=True)]

    sys.stderr.write("Reading alignments...\n")
    for r in regions:
        for a in r:
            if read_lim is not None and reads_on_target + reads_off_target > read_lim:
                break
            if a.query_name != last:
                qlen = None # we have to catch it because it will only be known in one of the several alignments in BAM file
                last = a.query_name

            if qlen is None and a.query_length > 0:
                qlen = a.query_length

            if a.reference_name in ref.chr_idx:
                c = ref.chr_idx[a.reference_name]
                l = af.lengths[af.references.index(a.reference_name)]
                if ref.chr_covg[c] is None:
                    ref.chr_len[c] = l
                    ref.chr_covg[c] = numpy.zeros(l+1, dtype='u4')
                #ref.chr_covg[c][int(a.reference_start):int(a.reference_end)] += 1
                ref.chr_covg[c][int(a.reference_start)+(int(a.reference_end)-int(a.reference_start))//2] += 1
                for g in genes[c]:
                    if min(g[2]+gene_margin, a.reference_end) - max(g[1]-gene_margin, a.reference_start) > min_anchor:
                        _, qs, qe, ts, te = fix_sam_coords(a)
                        hits[a.query_name].append((a, (qs, qe, ts, te)))
                        if qlen is not None:
                            read_lengths[a.query_name] = qlen

                #-----------------
                written = False
                for g in genes[c]:
                    rst = int(g[1])
                    ren = int(g[2])
                    if a.reference_start <= ren and a.reference_end >= rst:
                        ovl = min(a.reference_end, ren) - max(a.reference_start, rst)
                        gene_covg[g] += ovl
                        total_ovl += ovl
                        total_on_target += a.reference_end-a.reference_start
                        reads_on_target += 1
                    if a.reference_start <= ren+enrich_margin and a.reference_end >= rst-enrich_margin:
                        if not written and outdir is not None:
                            a, qs, qe, ts, te = fix_sam_coords(a)
                            target_paf.write(f"{a.query_name}\t{qlen}\t{qs}\t{qe}\t{'-' if a.is_reverse else '+'}\t{a.reference_name}\t{l}\t{ts}\t{te}\t-1\t-1\t255\n")
                            written = True
                else:
                    reads_off_target += 1
                    if a.query_length > 2000:
                        long_off_target += 1
                total += a.reference_end - a.reference_start
                #-----------------

    # filter duplex from hits list
    to_remove = []
    for r in hits:
        if ';' in r: # a duplex read
            to_remove.extend(r.split(';'))
    for r in to_remove:
        if r in hits:
            del hits[r]

    if outdir is not None:
        target_paf.close()
        sys.stderr.write(f"Saving chromosome coverages to {outdir}/\n")
        for c in range(len(ref.chr_covg)):
            if ref.chr_covg[c] is not None:
                ref.chr_covg[c].tofile(f"{outdir}/{ref.chrom_names[c]}_covg.npy")


    # ----------------------------
    # adaptive sampling statistics
    # ----------------------------
    total_target_regions = 0
    for c in genes:
        for g in genes[c]:
            total_target_regions += int(g[2]) - int(g[1])

    print()
    print("---------------------------")
    print("|    Adaptive sampling    |")
    print("---------------------------")
    print(f"{total} nt aligned (avg covg ~{total/3e9:.3f}x)")
    print(f"{total_on_target} nt in reads overlapping targets ({total_on_target/total*100:.2f} %)")
    print(f"{total_ovl} nt overlapping regions ({total_ovl/total*100:.2f} %)")
    print(f"{total_target_regions} nt in target regions (~{total_target_regions/3e9*100:.2f} % of genome)")
    print(f"Approx. enrichment: {(total_ovl/total) / (total_target_regions/3e9) : .2f}X")
    print(f"{reads_on_target} reads on target ({reads_on_target/(reads_on_target+reads_off_target)*100:.2f} %)")
    print(f"{total_on_target/(reads_on_target if reads_on_target > 0 else 1):.0f} nt avg for on target reads")
    print(f"{(total-total_on_target)/reads_off_target:.0f} nt avg for off target reads")
    print(f"{long_off_target} long off-target reads (>2Kbp)")
    for c in genes:
        for g in genes[c]:
            print(f"{g[0]} -- {ref.chrom_names[c]}, {g[1]}-{g[2]}: {gene_covg[g]} nt aligned ({gene_covg[g]/(int(g[2])-int(g[1])):.2f}x covg)")


    # ----------------
    # fusion detection
    # ----------------
    print()
    print("---------------------------")
    print(" Fusion detection")
    print("---------------------------")

    fusions = {}
    for read in hits:
        overlaps = set()
        found_fusion = False # flag to indicate whether a fusion has been marked so that only one is called for each read
        if read not in read_lengths:
            read_lengths[read] = hits[read][0][0].infer_query_length()
        qlen = read_lengths[read]
        for i in range(len(hits[read])):
            h0, (qs0, qe0, ts0, te0) = hits[read][i]
            c0 = ref.chr_idx[h0.reference_name]
            for j in range(i+1, len(hits[read])):
                h1, (qs1, qe1, ts1, te1) = hits[read][j]
                c1 = ref.chr_idx[h1.reference_name]

                g0 = (c0, (h0.reference_start+(h0.reference_end-h0.reference_start)//2)//1000000) # (chrom, loc[Mbp])
                g1 = (c1, (h1.reference_start+(h1.reference_end-h1.reference_start)//2)//1000000)

                # assign gene names instead of coordinates to those matching one of our known targets
                for g in genes[c0]:
                    if min(g[2]+gene_margin, h0.reference_end) - max(g[1]-gene_margin, h0.reference_start) > min_anchor:
                        g0 = g[0]
                for g in genes[c1]:
                    if min(g[2]+gene_margin, h1.reference_end) - max(g[1]-gene_margin, h1.reference_start) > min_anchor:
                        g1 = g[0]

                if g0 == g1 or type(g0) != type("str") or type(g1) != type("str") or ("DUX4" in g0 and "DUX4" in g1):
                    continue

                if min(qe0, qe1) - max(qs0, qs1) > 100: # they significantly overlap in the read
                    #continue
                    pass # not a hard rule right now
                if c0 == c1 and min(h0.reference_end, h1.reference_end) - max(h0.reference_start, h1.reference_start) > -10000: # they are even close in the target
                    continue

                # check if either anchor overlaps a repeat element
                h0_rng = numpy.zeros((h0.reference_end-h0.reference_start), dtype='u1')
                h1_rng = numpy.zeros((h1.reference_end-h1.reference_start), dtype='u1')
                for rp in repeats[c0]:
                    g0_ovl = min(h0.reference_end, rp[1]) - max(h0.reference_start, rp[0])
                    if g0_ovl > 0:
                        h0_rng[max(rp[0]-h0.reference_start, 0):min(rp[1]-h0.reference_start, h0_rng.shape[0])] = 1
                for rp in repeats[c1]:
                    g1_ovl = min(h1.reference_end, rp[1]) - max(h1.reference_start, rp[0])
                    if g1_ovl > 0:
                        h1_rng[max(rp[0]-h1.reference_start, 0):min(rp[1]-h1.reference_start, h0_rng.shape[0])] = 1
                g0_rp_overlap = h0_rng.sum()
                g1_rp_overlap = h1_rng.sum()

                key = (g0,g1) if (type(g0) == type("str") and type(g0) != type(g1)) or (type(g0) == type(g1) and g0 < g1) else (g1,g0)
                if not key in fusions:
                    fusions[key] = [0,0,[]]
                fusions[key][0] += 1
                fusions[key][2].append((h0, h1))

                if h0.reference_end - h0.reference_start - g0_rp_overlap < min_anchor or h1.reference_end - h1.reference_start - g1_rp_overlap < min_anchor:
                    # possible repetitive overlap
                    fusions[key][1] += 1

                found_fusion = True
                break
            if found_fusion:
                break

    fusions = sorted([(f,fusions[f]) for f in fusions], key=lambda a:a[1][0])
    for f,(ct,rep,pairs) in fusions:

        dup = 0
        # remove cryptic duplex reads if they are on the same channel within 100 rn ("read number" but not actual read number...) of each other, or 10 seconds if rn is unavailable
        i = 0
        while i < len(pairs):
            if not pairs[i][0].has_tag("ch"):
                sys.stderr.write(f"WARNING: read missing ch tag: {pairs[i][0].query_name}\n")
                i += 1
                continue
            j = i+1
            while j < len(pairs):
                if not pairs[j][0].has_tag("ch"):
                    sys.stderr.write(f"WARNING: read missing ch tag: {pairs[j][0].query_name}\n")
                    j += 1
                    continue
                if pairs[i][0].get_tag("ch") == pairs[j][0].get_tag("ch"):
                    # some reads have -1 or missing rn tag, use: st:Z:2024-11-09T03:41:02.226+00:00
                    rn0 = pairs[i][0].get_tag("rn") if pairs[i][0].has_tag("rn") else -1
                    rn1 = pairs[j][0].get_tag("rn") if pairs[j][0].has_tag("rn") else -1
                    diff = None
                    if rn0 == -1 or rn1 == -1: # missing or natively -1
                        # use start time + duration instead to set cutoff for how long 2nd read must follow first
                        if pairs[i][0].has_tag("st"):
                            st0 = datetime.fromisoformat(pairs[i][0].get_tag("st").replace("Z", "+00:00")).timestamp()
                        if pairs[j][0].has_tag("st"):
                            st1 = datetime.fromisoformat(pairs[j][0].get_tag("st").replace("Z", "+00:00")).timestamp()
                        # if duration doesn't exist, set an estimated duration of (read length / 400) seconds
                        if pairs[i][0].has_tag("du"):
                            du0 = pairs[i][0].get_tag("du")
                        else:
                            du0 = read_lengths[pairs[i][0].query_name] / 400
                        if pairs[j][0].has_tag("du"):
                            du1 = pairs[j][0].get_tag("du")
                        else:
                            du1 = read_lengths[pairs[j][0].query_name] / 400
                        diff = (st1 - (st0 + du0)) if st0 < st1 else (st0 - (st1 + du1))
                    # cryptic duplex are expected to be within 100 "read number" or 10 seconds, conservatively
                    if (diff is None and abs(rn0 - rn1) < 100) or (diff is not None and diff < 10):
                        if diff is None:
                            sys.stderr.write(f"Detected cryptic duplex: {pairs[i][0].query_name} ch {pairs[i][0].get_tag('ch')} rn {pairs[i][0].get_tag('rn')} ~ {pairs[j][0].query_name} ch {pairs[j][0].get_tag('ch')} rn {pairs[j][0].get_tag('rn')}\n")
                        else:
                            sys.stderr.write(f"Detected cryptic duplex: {pairs[i][0].query_name} ch {pairs[i][0].get_tag('ch')} time {st0 + (pairs[i][0].get_tag('du') if st0<st1 else 0)} ~ {pairs[j][0].query_name} ch {pairs[j][0].get_tag('ch')} time {st1 + (pairs[j][0].get_tag('du') if st1<st0 else 0)}\n")
                        dup += 1
                        # we're going to semi-arbitrarily get rid of the second reads of the putative duplex
                        # I think it's defensible because it's either the second in the file (the back strand), or the second in the alignment, so probably covers less genome
                        pairs.pop(j)
                        break # only one duplex partner can exist, don't need to keep looking
                j += 1
            i += 1

        print(f, f"{rep}/{ct-dup} deduplexed possibly in repetitive regions")
        if len(pairs) >= 1:
            bpt = find_breakpoint(f[0], f[1], pairs)


    # -----------------------
    # karyotype plot/coverage
    # -----------------------
    print()
    print("---------------------------")
    print("|       Karyotyping       |")
    print("---------------------------")
    x = 0
    plt.figure(figsize=(20,4), dpi=100)
    chr_locs = []
    bins = [None for i in range(len(ref.chroms))]
    for c in range(len(ref.chroms)):
        if ref.chr_covg[c] is None:
            print(f"chrom '{ref.chr_covg[c]}' coverage is missing - maybe there were no assigned reads")
            continue
        # mask repeats, Ns, enriched genes
        ref.chr_covg[c] = ma.masked_array(ref.chr_covg[c])
        for region in mask[c]:
            ref.chr_covg[c][region[0]:region[1]] = ma.masked
        bins[c] = numpy.zeros((ref.chr_covg[c].shape[0]//bin_size + 1, 4), dtype='u4') # min, median, max, total
        bin_mask = numpy.zeros((ref.chr_covg[c].shape[0]//bin_size + 1), dtype='bool')
        for i in range(bins[c].shape[0]):
            st = i * bin_size
            en = st + bin_size
            n_sbins = min(bin_size//sbin_size + (1 if bin_size%sbin_size > 0 else 0), (ref.chr_covg[c].shape[0]-st)//sbin_size)
            sbins = numpy.zeros((n_sbins), dtype='u4')
            sbin_mask = numpy.zeros((n_sbins), dtype='bool')
            for j in range(sbins.shape[0]):
                sbin_tot = ref.chr_covg[c][st+j*sbin_size:st+(j+1)*sbin_size].sum()
                sbin_ct = ref.chr_covg[c][st+j*sbin_size:st+(j+1)*sbin_size].count() # count unmasked values
                if sbin_ct > sbin_size * 0.25:
                    sbin_mask[j] = True
                    sbin_tot *= sbin_size/sbin_ct
                    sbins[j] = sbin_tot
                else:
                    sbin_mask[j] = False
            sbins = sbins[sbin_mask]
            if sbins.shape[0] == 0:
                bin_mask[i] = False
            else:
                bin_mask[i] = True
                bins[c][i,0] = sbins.min()
                bins[c][i,1] = numpy.median(sbins)
                bins[c][i,2] = sbins.max()
                bins[c][i,3] = sbins.sum()
        bins[c] = bins[c][bin_mask,:]
        med = numpy.median(bins[c][:,1])
        print(f"{ref.chroms[c]}: {ref.chr_len[c]} nt, masked median depth/sbin ({sbin_size}): {med:.2f}")
        plt.scatter([x+i for i in range(bins[c].shape[0]) if bins[c][i,1] != 2**16-1], [b for b in bins[c][:,1] if b != 2**16-1], color="blue", marker='.')
        plt.plot([x, x+bins[c].shape[0]-1],[med,med], color="red", linestyle="solid", linewidth=3)

        chr_locs.append(x+bins[c].shape[0]/2)
        x += bins[c].shape[0]
        plt.plot([x+5, x+5], [0, 2**16-1], color="black")
        x += 10

    plt.xticks(chr_locs, ref.chrom_names, rotation='vertical')
    plt.ylim((0,numpy.percentile(numpy.concatenate([b[:,2] for b in bins]), 99.9)))
    plt.xlim((0,x-10))
    plt.xlabel("Chromosome")
    plt.ylabel("Reads per Mbp")
    plt.title("Karyotype")
    plt.tight_layout()
    plt.savefig(outfig)


# g0 and g1 are fusion partners, in fixed alphabetical order
def find_breakpoint(g0, g1, pairs):
    breakpoint_clusters = []
    # a0/a1 are alignments to g0/g1, respectively
    for a0, a1 in pairs:
        _, qs0, qe0, ts0, te0 = fix_sam_coords(a0)
        _, qs1, qe1, ts1, te1 = fix_sam_coords(a1)
        print()
        print(f"  {a0.query_name} : {qs0} - {qe0} {'-' if a0.is_reverse else '+'} == {a0.reference_name} : {ts0} - {te0}")
        print(f"  {a1.query_name} : {qs1} - {qe1} {'-' if a1.is_reverse else '+'} == {a1.reference_name} : {ts1} - {te1}")
        if qe0 > qe1:
            if a0.is_reverse:
                g0_bpt = te0
            else:
                g0_bpt = ts0
            if a1.is_reverse:
                g1_bpt = ts1
            else:
                g1_bpt = te1
            insert_nt = qs0 - qe1
            print(f"  {g1} {a1.reference_name} {g1_bpt} :: {insert_nt} nt :: {g0} {a0.reference_name} {g0_bpt}")
        else:
            if a1.is_reverse:
                g1_bpt = te1
            else:
                g1_bpt = ts1
            if a0.is_reverse:
                g0_bpt = ts0
            else:
                g0_bpt = te0
            insert_nt = qs1 - qe0
            print(f"  {g0} {a0.reference_name} {g0_bpt} :: {insert_nt} nt :: {g1} {a1.reference_name} {g1_bpt}")
        g0_dir = '|->' if (qe0 > qe1) == (not a0.is_reverse) else '<-|'
        g1_dir = '|->' if (qe1 > qe0) == (not a1.is_reverse) else '<-|'
        for bpt0, dir0, bpt1, dir1, seqs in breakpoint_clusters:
            if abs(bpt0 - g0_bpt) < 20 and abs(bpt1 - g1_bpt) < 20 and g0_dir == dir0 and g1_dir == dir1:
                seqs.append((a0.query_sequence if a0.query_sequence is not None else a1.query_sequence, a0, a1))
                break
        else:
            breakpoint_clusters.append((g0_bpt, g0_dir, g1_bpt, g1_dir, [(a0.query_sequence if a0.query_sequence is not None else a1.query_sequence, a0, a1)]))

    for bpt0, dir0, bpt1, dir1, seqs in breakpoint_clusters:
        print("  ", g0, bpt0, dir0, "::", g1, bpt1, dir1, f"{len(seqs)} reads")

# PAF and BAM files store query coordinates differently - BAM have to be converted back to the original strand coordinates before comparison
def fix_sam_coords(aln):
    qlen = aln.infer_read_length()
    # query_alignment_start IGNORES hard-clipped bases, so we have to add them back to the beginning by checking the cigar string
    hard_clipped = 0
    for i in range(len(aln.cigarstring)):
        if aln.cigarstring[i] in 'MIDNSHP=X':
            if aln.cigarstring[i] == 'H':
                hard_clipped = int(aln.cigarstring[0:i])
            break
    qs = aln.query_alignment_start + hard_clipped # 0-indexed
    qe = aln.query_alignment_end + hard_clipped
    ts = aln.reference_start
    te = aln.reference_end
    if aln.is_reverse:
        tmp = qlen - qe
        qe = qlen - qs
        qs = tmp
    return (aln, qs, qe, ts, te)

if __name__ == "__main__":
    parser = argparse.ArgumentParser("Call karyotype and gene fusions/translocations from whole-genome nanopore seq BAM file")
    parser.add_argument("bam", help="BAM of reads to hg38 (mm2 -x map-ont)")
    parser.add_argument("bed", help="BED file including target genes")
    parser.add_argument("repeats", help="RepeatMasker BED file")
    parser.add_argument("cov", help="Output file for coverage figure")
    parser.add_argument("--read_lim", help="Maximum reads to process (default is all)", type=int)
    parser.add_argument("--outdir", help="Output directory for bigger results")
    parser.add_argument("--full", help="Assess full file, including off-target reads, in sorted BAM", action="store_true", default=False)
    parser.add_argument("--genes", help="Evaluate only the given genes (must be in the enrichment set)", nargs='+')
    args = parser.parse_args()
    main(args.bam, args.bed, args.repeats, args.cov, args.read_lim, args.outdir, args.full, [g.lower() for g in args.genes] if args.genes is not None else [])
